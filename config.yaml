base_url: 'url' # URL of your actual LLM backend
model_name: 'TheBloke/Llama-2-7b-Chat-GPTQ' # The model used for processing
branch: 'main' # What branch to use from HuggingFace
device: 'auto' # What device to select, see LLMLingua Docs for more info
ratio: 0.5 # What the compression ratio should be
rank_method: 'llmlingua' # See LLMLingua Docs for more info
keep_split: True # Keep newlines intact?
# Experimental
sentence_level_filter: false # Currently broken
force_context: false # Currently broken
split_instruction: true # Should instructions be split from the prompt and processed separately?
instruction_regex: '(### Instruction)(.|\n)*?(?=### Response|### Input|\[Summary:)' # The Regex to get the full instruction set without Response

# See the files 'ST Context Template - Netrve Alpaca.json' and 'ST Instruct Template - Netrve Alpaca.json' for how my setup looks like
